# Recast Homeworks as AI Tutoring Sessions

Here's a simple AI homework assignment. [Bray 2024](https://pubsonline.informs.org/doi/abs/10.1287/inte.2023.0053) discusses such AI homeworks at length:

> To establish the students' preference for the AI tutoring sessions, S&eacute;bastien Martin and I conducted a preregistered randomized control trial that split my elective class into two random groups for each homework, one of which received an AI version of the assignment; the other, an RMarkdown version [@Martin2024]. The AI homeworks were custom-made GPTs that had the questions, answers, and teaching instructions preloaded into the prompt, whereas the RMarkdown homeworks were interactive slide decks that could run code, analogous to Jupyter Notebooks, that provided the same study questions and answers. The students who received the RMarkdown assignments could use ChatGPT to do the homework, so rather than compare AI work with non-AI work, the experiment compared two different versions of AI work: using ChatGPT as an undifferentiated black box---a generic problem-solving platform, free of context---versus using it as a contextualized tutor---an entity that guides the study session as the professor sees fit. 
>
For each randomly assigned homework, we asked students, "Please rate your experience with the homework assignment" from 1 (very negative experience) to 5 (very positive experience), and "How helpful do you think this assignment was for your quiz preparation?" ranked from 1 (very unhelpful) to 5 (very helpful). Figure \ref{f:aiIsBetter} depicts the survey response distributions. The results clearly distinguish between AI-as-black-box and AI-as-tutor: changing the modality from RMarkdown to custom-made GPT increased the average homework experience score from `r read_rds("stats/ai_hws_are_better_experience_rating_FALSE.rds")` to `r read_rds("stats/ai_hws_are_better_experience_rating_TRUE.rds")` and increased the average quiz-preparation helpfulness score from `r read_rds("stats/ai_hws_are_better_helpfulness_rating_FALSE.rds")` to `r read_rds("stats/ai_hws_are_better_helpfulness_rating_TRUE.rds")`, differences that are both significantly positive at the $p = 0.0005$ level.
 
![Distribution of survey responses, from @Martin2024\label{f:aiIsBetter}](https://www.dropbox.com/scl/fi/df2e6dqzesoxh0dogu4n3/ai_hw_is_better.jpg?rlkey=31vuk30p5dqwolokdhaf72n4p&dl=1){width=100%}

> The following Slack message helps put Figure \ref{f:aiIsBetter}'s results into context:

>> Hello Professor, thanks for leaning so heavily on using ChatGPT as a learning partner. I really enjoy the ChatGPT exercises you sent over. In fact, I've listed out a few "Aha!" moments I had while going through your exercises:
>>
>> Instant Help at Any Resolution: You can get instant help when you don't know how (or why) something works. And ChatGPT allows you to zoom into any level of information (which a static textbook cannot). For example, I can ask a simple question like "What does wday() do" to something more complex like "Why does performing calculations in log space prevent numerical overload/underload issues?"
>>
>> Contextual Suggestions for holistic learning: ChatGPT ends up teaching you auxiliary materials related to a concept ("out of syllabus" stuff if you will) that helps you develop a more holistic understanding of the subject. For example, in one of the problems, it suggested that performing calculations in log space prevents numerical overload/underload errors. This is not important to our focus in R, but it helped me learn an interesting concept in programming on the fly. And as always, it helps us zoom into any levels.
>>
>> Accelerated improvement cycle: I actually learnt the pipe notation even before it was introduced in class because ChatGPT used it in a previous HW assignment. Since ChatGPT might be a better coder than us, we are basically learning by observing an expert on the task. And I can also get instant feedback on what I'm doing wrong (or inefficiently), and how I can improve it. This leads to much faster learning cycle than when I had to do something wrong for a long time before someone corrected me (or I corrected myself).
>>
>>  Staying in the flow: As a neurodivergent student, staying on the task is sometimes very hard for me. I have had times in the past where a HW problem would spark an idea, and before I knew it, I am watching this 3 hour documentary on how the space-economy works in EVE:Online. Doing the practice in ChatGPT has reduced this distractibility. I can still ask it questions about things outside the quiz (for example, why F1 races are only held on Sun), but it always steers me back to finishing the next problem in the HW, which is a boon.

